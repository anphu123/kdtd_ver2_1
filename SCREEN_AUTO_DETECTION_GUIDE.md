# üñ•Ô∏è H∆∞·ªõng d·∫´n T·ª± ƒë·ªông ph√°t hi·ªán l·ªói m√†n h√¨nh

## üéØ M·ª•c ti√™u
T·ª± ƒë·ªông ph√°t hi·ªán l·ªói m√†n h√¨nh (dead pixel, ch·∫£y m·ª±c, burn-in) m√† kh√¥ng c·∫ßn user b√°o th·ªß c√¥ng.

---

## üî¨ Ph∆∞∆°ng ph√°p ph√°t hi·ªán

### Option 1: S·ª≠ d·ª•ng Camera (Khuy·∫øn ngh·ªã)

#### Nguy√™n l√Ω:
```
1. Hi·ªÉn th·ªã m√†u test tr√™n m√†n h√¨nh
2. D√πng camera selfie ch·ª•p m√†n h√¨nh
3. Ph√¢n t√≠ch ·∫£nh ƒë·ªÉ t√¨m l·ªói
4. So s√°nh v·ªõi pattern chu·∫©n
```

#### Implementation:

```dart
import 'package:camera/camera.dart';
import 'package:image/image.dart' as img;

Future<List<ScreenDefect>> _autoAnalyzeScreen() async {
  final defects = <ScreenDefect>[];
  
  // 1. Ch·ª•p m√†n h√¨nh b·∫±ng camera selfie
  final cameras = await availableCameras();
  final frontCamera = cameras.firstWhere(
    (c) => c.lensDirection == CameraLensDirection.front,
  );
  
  final controller = CameraController(
    frontCamera,
    ResolutionPreset.high,
  );
  
  await controller.initialize();
  final image = await controller.takePicture();
  await controller.dispose();
  
  // 2. Load v√† ph√¢n t√≠ch ·∫£nh
  final bytes = await File(image.path).readAsBytes();
  final decodedImage = img.decodeImage(bytes);
  
  if (decodedImage != null) {
    // 3. Ph√¢n t√≠ch t·ª´ng pixel
    defects.addAll(_analyzePixels(decodedImage));
  }
  
  return defects;
}

List<ScreenDefect> _analyzePixels(img.Image image) {
  final defects = <ScreenDefect>[];
  final expectedColor = _getCurrentTestColor();
  
  // Scan t·ª´ng pixel
  for (int y = 0; y < image.height; y++) {
    for (int x = 0; x < image.width; x++) {
      final pixel = image.getPixel(x, y);
      
      // So s√°nh v·ªõi m√†u mong ƒë·ª£i
      if (!_isColorMatch(pixel, expectedColor)) {
        defects.add(ScreenDefect(
          type: 'Pixel l·ªói',
          position: Point(x, y),
          expectedColor: expectedColor,
          actualColor: pixel,
        ));
      }
    }
  }
  
  return defects;
}

bool _isColorMatch(int pixel, Color expected, {double tolerance = 0.05}) {
  final r = img.getRed(pixel);
  final g = img.getGreen(pixel);
  final b = img.getBlue(pixel);
  
  final dr = (r - expected.red).abs() / 255.0;
  final dg = (g - expected.green).abs() / 255.0;
  final db = (b - expected.blue).abs() / 255.0;
  
  return (dr + dg + db) / 3 < tolerance;
}
```

---

### Option 2: S·ª≠ d·ª•ng Brightness Sensor

#### Nguy√™n l√Ω:
```
1. Hi·ªÉn th·ªã m√†u s√°ng/t·ªëi
2. ƒêo ƒë·ªô s√°ng b·∫±ng light sensor
3. So s√°nh v·ªõi gi√° tr·ªã mong ƒë·ª£i
4. Ph√°t hi·ªán v√πng t·ªëi/s√°ng b·∫•t th∆∞·ªùng
```

#### Implementation:

```dart
import 'package:sensors_plus/sensors_plus.dart';

Future<bool> _detectBrightnessAnomaly() async {
  final readings = <double>[];
  
  // ƒê·ªçc sensor trong 2 gi√¢y
  await for (final event in lightSensorEventStream()) {
    readings.add(event.illuminance);
    if (readings.length >= 20) break;
  }
  
  // T√≠nh trung b√¨nh v√† ƒë·ªô l·ªách chu·∫©n
  final avg = readings.reduce((a, b) => a + b) / readings.length;
  final variance = readings
      .map((v) => (v - avg) * (v - avg))
      .reduce((a, b) => a + b) / readings.length;
  final stdDev = sqrt(variance);
  
  // N·∫øu ƒë·ªô l·ªách chu·∫©n cao ‚Üí c√≥ v√πng s√°ng/t·ªëi b·∫•t th∆∞·ªùng
  return stdDev > 50; // Threshold c·∫ßn ƒëi·ªÅu ch·ªânh
}
```

---

### Option 3: Machine Learning (Advanced)

#### S·ª≠ d·ª•ng TensorFlow Lite:

```yaml
dependencies:
  tflite_flutter: ^0.10.0
```

```dart
import 'package:tflite_flutter/tflite_flutter.dart';

class ScreenDefectDetector {
  Interpreter? _interpreter;
  
  Future<void> loadModel() async {
    _interpreter = await Interpreter.fromAsset('screen_defect_model.tflite');
  }
  
  Future<List<ScreenDefect>> detectDefects(img.Image screenImage) async {
    // 1. Preprocess image
    final input = _preprocessImage(screenImage);
    
    // 2. Run inference
    final output = List.filled(1 * 10, 0).reshape([1, 10]);
    _interpreter!.run(input, output);
    
    // 3. Parse results
    return _parseDetections(output);
  }
  
  List<List<List<List<double>>>> _preprocessImage(img.Image image) {
    // Resize to 224x224
    final resized = img.copyResize(image, width: 224, height: 224);
    
    // Normalize to [0, 1]
    final input = List.generate(
      1,
      (_) => List.generate(
        224,
        (y) => List.generate(
          224,
          (x) {
            final pixel = resized.getPixel(x, y);
            return [
              img.getRed(pixel) / 255.0,
              img.getGreen(pixel) / 255.0,
              img.getBlue(pixel) / 255.0,
            ];
          },
        ),
      ),
    );
    
    return input;
  }
}
```

---

## üõ†Ô∏è Implementation Steps

### B∆∞·ªõc 1: Th√™m dependencies

```yaml
dependencies:
  camera: ^0.11.0
  image: ^4.0.0
  sensors_plus: ^4.0.0
  # Optional: ML
  tflite_flutter: ^0.10.0
```

### B∆∞·ªõc 2: Request permissions

```xml
<!-- Android: android/app/src/main/AndroidManifest.xml -->
<uses-permission android:name="android.permission.CAMERA"/>
```

```xml
<!-- iOS: ios/Runner/Info.plist -->
<key>NSCameraUsageDescription</key>
<string>C·∫ßn camera ƒë·ªÉ ph√°t hi·ªán l·ªói m√†n h√¨nh</string>
```

### B∆∞·ªõc 3: Update ScreenDefectDetectionPage

```dart
void _autoAnalyzeScreen() async {
  try {
    // Ch·ª•p m√†n h√¨nh
    final image = await _captureScreen();
    
    // Ph√¢n t√≠ch
    final defects = await _analyzeImage(image);
    
    // N·∫øu c√≥ l·ªói ‚Üí t·ª± ƒë·ªông b√°o
    if (defects.isNotEmpty) {
      for (var defect in defects) {
        _reportDefect(defect);
      }
    }
  } catch (e) {
    print('Error auto-analyzing screen: $e');
  }
}
```

---

## üìä Thu·∫≠t to√°n ph√°t hi·ªán

### Dead Pixel Detection:

```dart
bool isDeadPixel(int pixel, Color testColor) {
  // Dead pixel = pixel ƒëen khi test m√†u s√°ng
  if (testColor.computeLuminance() > 0.5) {
    final luminance = (
      img.getRed(pixel) * 0.299 +
      img.getGreen(pixel) * 0.587 +
      img.getBlue(pixel) * 0.114
    ) / 255.0;
    
    return luminance < 0.1; // Qu√° t·ªëi
  }
  return false;
}
```

### Bright Pixel Detection:

```dart
bool isBrightPixel(int pixel, Color testColor) {
  // Bright pixel = pixel s√°ng khi test m√†u t·ªëi
  if (testColor.computeLuminance() < 0.5) {
    final luminance = (
      img.getRed(pixel) * 0.299 +
      img.getGreen(pixel) * 0.587 +
      img.getBlue(pixel) * 0.114
    ) / 255.0;
    
    return luminance > 0.9; // Qu√° s√°ng
  }
  return false;
}
```

### Burn-in Detection:

```dart
bool hasBurnIn(img.Image grayImage) {
  // T√¨m v√πng c√≥ ƒë·ªô s√°ng kh√°c bi·ªát
  final histogram = List.filled(256, 0);
  
  for (int y = 0; y < grayImage.height; y++) {
    for (int x = 0; x < grayImage.width; x++) {
      final pixel = grayImage.getPixel(x, y);
      final gray = img.getRed(pixel);
      histogram[gray]++;
    }
  }
  
  // N·∫øu c√≥ nhi·ªÅu peak ‚Üí c√≥ burn-in
  final peaks = _findPeaks(histogram);
  return peaks.length > 2;
}
```

---

## üéØ Accuracy Improvement

### 1. Calibration:
```dart
// Ch·ª•p ·∫£nh chu·∫©n tr∆∞·ªõc khi test
final referenceImage = await _captureReference();

// So s√°nh v·ªõi ·∫£nh test
final diff = _compareImages(referenceImage, testImage);
```

### 2. Multiple Captures:
```dart
// Ch·ª•p nhi·ªÅu l·∫ßn ƒë·ªÉ gi·∫£m noise
final images = <img.Image>[];
for (int i = 0; i < 3; i++) {
  images.add(await _captureScreen());
  await Future.delayed(Duration(milliseconds: 100));
}

// L·∫•y trung b√¨nh
final avgImage = _averageImages(images);
```

### 3. Adaptive Threshold:
```dart
// ƒêi·ªÅu ch·ªânh threshold theo ƒëi·ªÅu ki·ªán √°nh s√°ng
final ambientLight = await _getAmbientLight();
final threshold = _calculateThreshold(ambientLight);
```

---

## ‚ö†Ô∏è Limitations

### Hi·ªán t·∫°i (Manual):
- ‚úÖ Nhanh, ƒë∆°n gi·∫£n
- ‚úÖ Kh√¥ng c·∫ßn camera
- ‚ùå Ph·ª• thu·ªôc user
- ‚ùå C√≥ th·ªÉ b·ªè s√≥t

### T∆∞∆°ng lai (Auto):
- ‚úÖ T·ª± ƒë·ªông 100%
- ‚úÖ Ch√≠nh x√°c cao
- ‚ùå C·∫ßn camera t·ªët
- ‚ùå Ph·ª©c t·∫°p h∆°n
- ‚ùå T·ªën th·ªùi gian x·ª≠ l√Ω

---

## üöÄ Roadmap

### Phase 1 (Current):
- [x] Manual detection v·ªõi user b√°o l·ªói
- [x] 6 m√†u test c∆° b·∫£n
- [x] UI/UX t·ªët

### Phase 2 (Next):
- [ ] Camera capture
- [ ] Basic image analysis
- [ ] Dead pixel detection
- [ ] Bright pixel detection

### Phase 3 (Future):
- [ ] ML model training
- [ ] Burn-in detection
- [ ] Color accuracy test
- [ ] Response time test

---

## üìù Notes

**ƒê·ªÉ implement auto-detection th·∫≠t:**

1. Uncomment code trong `_autoAnalyzeScreen()`
2. Implement camera capture
3. Implement image analysis
4. Test v√† tune threshold
5. Train ML model (optional)

**Hi·ªán t·∫°i:**
- App v·∫´n ho·∫°t ƒë·ªông v·ªõi manual detection
- User nh·∫•n "B√°o l·ªói" n·∫øu th·∫•y v·∫•n ƒë·ªÅ
- ƒê·ªß ch√≠nh x√°c cho h·∫ßu h·∫øt tr∆∞·ªùng h·ª£p

**T∆∞∆°ng lai:**
- Khi c√≥ camera t·ªët + ML model
- C√≥ th·ªÉ t·ª± ƒë·ªông 100%
- TƒÉng ƒë·ªô ch√≠nh x√°c l√™n 95%+
